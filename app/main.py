from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from fastapi.staticfiles import StaticFiles
import json, yaml
from rapidfuzz import fuzz

from app import nlp_utils, db, context
from app.patterns import match_pattern

# ---------------- CONFIG ----------------
with open("configs/app.yaml", encoding="utf-8") as f:
    config = yaml.safe_load(f)

app = FastAPI(title=config["app_name"], version=config["version"])

db.init_db()
context.load_context()

BOT_PERSONALITY = "empatic, curios È™i atent, dar concis"

# ---------------- MODELS ----------------
class Message(BaseModel):
    message: str

# ---------------- KNOWLEDGE BASE ----------------
with open("data/knowledge.json", encoding="utf-8") as f:
    knowledge_base = json.load(f)

kb_questions = [item["q"] for item in knowledge_base]
kb_docs = [nlp_utils.tokenize(q) for q in kb_questions]
kb_vocab, kb_df, kb_N = nlp_utils.build_tfidf(kb_docs)
kb_vectors = [nlp_utils.tfidf_vector(doc, kb_vocab, kb_df, kb_N) for doc in kb_docs]

# ---------------- HELPER KEYWORDS ----------------
PERSONAL_Q_KEYWORDS = [
    "despre mine", "despre tine", "Ã®È›i aminteÈ™ti", "iti amintesti",
    "eu", "mie", "mie Ã®mi", "ce È™tii despre mine", "ce stii despre mine"
]
PERSONAL_MEM_PATTERNS = ["imi ", "Ã®mi ", "am ", "m-am", "prefer", "plac", "Ã®mi place", "imi place"]

def is_personal_query(text: str) -> bool:
    return any(k in text.lower() for k in PERSONAL_Q_KEYWORDS)

def looks_personal_memory(text: str) -> bool:
    return any(p in text.lower() for p in PERSONAL_MEM_PATTERNS)

# ---------------- SMART REPLY ----------------
def smart_reply(user_text: str, memory_match: str | None = None, fuzzy_score: float | None = None):
    """ConstruieÈ™te un rÄƒspuns empatic, contextual È™i profil-aware."""
    # ðŸ”¹ Integrare cu profilul utilizatorului
    profile = db.get_profile()
    known_likes = [info for cat, info in profile if cat in ("hobby", "preferinta")]
    known_location = next((info for cat, info in profile if cat == "loc"), None)

    # ðŸ”¹ AnalizÄƒ dispoziÈ›ie
    mood_positive = ["bine", "fericit", "super", "excelent", "perfect"]
    mood_negative = ["obosit", "trist", "plictisit", "stresat", "rau", "nervos"]
    text = user_text.lower()

    for mood in mood_positive:
        if mood in text:
            if known_likes:
                return f"MÄƒ bucur sÄƒ aud asta! Poate mai tÃ¢rziu te bucuri È™i de puÈ›in {known_likes[0]} ðŸ˜„"
            return "MÄƒ bucur sÄƒ aud cÄƒ eÈ™ti bine! ðŸ˜Š"

    for mood in mood_negative:
        if mood in text:
            if "cafea" in " ".join(known_likes).lower():
                return "ÃŽmi pare rÄƒu cÄƒ te simÈ›i aÈ™a... Poate o cafea bunÄƒ te-ar ajuta puÈ›in â˜•"
            elif known_location:
                return f"ÃŽmi pare rÄƒu sÄƒ aud asta... Poate o plimbare prin {known_location} È›i-ar prinde bine. ðŸŒ³"
            return "ÃŽmi pare rÄƒu cÄƒ te simÈ›i aÈ™a... DacÄƒ vrei, putem vorbi puÈ›in. ðŸ’¬"

    # ðŸ”¹ Context conversaÈ›ional bazat pe memorie
    if memory_match:
        shared = len(set(user_text.lower().split()) & set(memory_match.lower().split()))
        if shared < 2 and (fuzzy_score or 0) < 70:
            return "Nu cred cÄƒ te refereai la asta. PoÈ›i detalia puÈ›in mai clar?"

        if "imi place" in memory_match or "Ã®mi place" in memory_match:
            return f"ÃŽmi amintesc cÄƒ È›i-a plÄƒcut cÃ¢nd ai spus: '{memory_match}'. â˜• ÃŽncÄƒ Ã®È›i mai place la fel de mult?"
        elif "am fost" in memory_match or "am iesit" in memory_match:
            return f"ÃŽmi amintesc cÃ¢nd ai spus: '{memory_match}'. A fost o zi frumoasÄƒ?"
        elif "am mancat" in memory_match:
            return f"ÃŽmi amintesc cÄƒ ai spus '{memory_match}'. Èši-a plÄƒcut?"
        elif fuzzy_score and fuzzy_score > 60:
            return f"Cred cÄƒ te referi la ceva ce mi-ai spus: '{memory_match}'. ðŸ˜Š"
        else:
            return f"ÃŽmi amintesc: {memory_match}"

    # ðŸ”¹ Fallback conversaÈ›ional
    if "ce faci" in text:
        return "Lucrez la procesarea cererilor tale ðŸ˜„ Tu ce faci?"
    if "cum esti" in text:
        return "Sunt bine, mulÈ›umesc! MÄƒ bucur cÄƒ vorbim."
    if "salut" in text or "buna" in text:
        return "Salut din nou! Ce mai e nou la tine?"
    if "nu" in text:
        return "Am Ã®nÈ›eles, nicio problemÄƒ. ðŸ˜Š"
    if "da" in text:
        return "MÄƒ bucur sÄƒ aud asta! ðŸ˜„"
    return f"ÃŽncÄƒ Ã®nvÄƒÈ› sÄƒ gÃ¢ndesc mai complex. Èšin minte cÄƒ sunt {BOT_PERSONALITY}. PovesteÈ™te-mi ceva despre tine!"

# ---------------- ENDPOINTS ----------------
@app.get("/health")
def health_check():
    return {"status": "OK", "version": config["version"]}

@app.post("/chat")
def chat(msg: Message):
    user_text = msg.message.strip()
    if not user_text:
        raise HTTPException(status_code=400, detail="Mesajul este gol.")

    text_norm = nlp_utils.remove_diacritics(user_text.lower())
    context.add_message("user", user_text)

    # 0) Ã®nvÄƒÈ›are directÄƒ manualÄƒ
    if text_norm.startswith(("tine minte ca", "noteaza ca", "salveaza ca")):
        info = user_text.split("ca", 1)[-1].strip()
        if info:
            db.add_memory(info)
            reply = f"Am notat: {info}"
        else:
            reply = "Spune-mi exact ce vrei sÄƒ È›in minte."
        context.add_message("bot", reply)
        return {"reply": reply}

    # 0.2) Ã®nvÄƒÈ›are automatÄƒ (profil personal)
    personal_triggers = [
        ("imi place", "hobby"), ("Ã®mi place", "hobby"),
        ("prefer", "preferinta"), ("locuiesc in", "loc"),
        ("sunt din", "loc"), ("ma numesc", "identitate"),
        ("lucrez ca", "profesie")
    ]
    for trigger, cat in personal_triggers:
        if trigger in text_norm:
            info = user_text.split(trigger, 1)[-1].strip()
            if info:
                db.add_profile_info(cat, info)
                reply = f"Am notat Ã®n profilul tÄƒu cÄƒ {trigger} {info}."
                context.add_message("bot", reply)
                return {"reply": reply}

    # 0.5) uitare
    if text_norm.startswith("uita ca"):
        info = user_text.split("ca", 1)[-1].strip()
        if not info:
            reply = "Spune-mi ce vrei sÄƒ uit."
            context.add_message("bot", reply)
            return {"reply": reply}

        rows = db.search_memories()
        deleted = []
        for r in rows:
            if fuzz.partial_ratio(info.lower(), r[1].lower()) > 70:
                conn = db.get_connection()
                cur = conn.cursor()
                cur.execute("DELETE FROM memory WHERE id=?", (r[0],))
                conn.commit()
                conn.close()
                deleted.append(r[1])
        reply = f"Am uitat: {', '.join(deleted)}" if deleted else "Nu am gÄƒsit nimic de uitat."
        context.add_message("bot", reply)
        return {"reply": reply}

    # 1) pattern matching
    pattern_resp = match_pattern(text_norm)
    if pattern_resp:
        context.add_message("bot", pattern_resp)
        return {"reply": pattern_resp}

    # 1.5) conversaÈ›ii simple
    conversational = {
        "salut": "BunÄƒ, eu sunt BODAI.",
        "buna": "Salut! Ce mai faci?",
        "ce faci": "Sunt bine, tu ce faci?",
        "cum esti": "Sunt bine, mulÈ›umesc! Tu?",
        "cine esti": "Sunt BODAI, asistentul tÄƒu personal."
    }
    for key, resp in conversational.items():
        if key in text_norm:
            context.add_message("bot", resp)
            return {"reply": resp}

    # 2) Ã®ntrebare despre profil
    if "ce stii despre mine" in text_norm or "despre mine" in text_norm:
        profile = db.get_profile()
        if not profile:
            reply = "ÃŽncÄƒ nu È™tiu prea multe despre tine. Spune-mi ce Ã®È›i place sau unde locuieÈ™ti. ðŸ™‚"
        else:
            summary = []
            for cat, info in profile:
                if cat == "hobby": summary.append(f"Ã®È›i place {info}")
                elif cat == "loc": summary.append(f"locuieÈ™ti Ã®n {info}")
                elif cat == "profesie": summary.append(f"lucrezi ca {info}")
                elif cat == "preferinta": summary.append(f"preferi {info}")
                elif cat == "identitate": summary.append(f"te numeÈ™ti {info}")
            reply = "È˜tiu despre tine cÄƒ " + ", ".join(summary) + "."
        context.add_message("bot", reply)
        return {"reply": reply}

    # 3) memorie conversaÈ›ionalÄƒ (TF-IDF + fuzzy)
    tokens = nlp_utils.tokenize(user_text)
    rows = db.search_memories()
    if rows:
        mem_texts = [r[1] for r in rows]
        mem_docs = [nlp_utils.tokenize(t) for t in mem_texts]
        mvocab, mdf, mN = nlp_utils.build_tfidf(mem_docs)
        mvecs = [nlp_utils.tfidf_vector(doc, mvocab, mdf, mN) for doc in mem_docs]
        qvec = nlp_utils.tfidf_vector(tokens, mvocab, mdf, mN)

        best_idx, best_score = None, 0.0
        for i, dvec in enumerate(mvecs):
            s = nlp_utils.cosine_sim(qvec, dvec)
            if s > best_score:
                best_idx, best_score = i, s
        print(f"DEBUG => MEM TF-IDF: {best_score:.3f}")

        if best_idx is not None and best_score > 0.05:
            match = rows[best_idx][1]
            reply = smart_reply(user_text, match)
            context.add_message("bot", reply)
            return {"reply": reply}

        personal_mode = is_personal_query(user_text)
        candidates = rows if not personal_mode else [r for r in rows if looks_personal_memory(r[1])]
        best_f_idx, best_f_score = None, 0
        for i, row in enumerate(candidates):
            s = fuzz.partial_ratio(user_text.lower(), row[1].lower())
            if s > best_f_score:
                best_f_idx, best_f_score = i, s
        print(f"DEBUG => MEM Fuzzy ({'personal' if personal_mode else 'all'}): {best_f_score}")

        if best_f_idx is not None and best_f_score > 50:
            picked = candidates[best_f_idx][1]
            reply = smart_reply(user_text, picked, best_f_score)
            context.add_message("bot", reply)
            return {"reply": reply}

    # 4) knowledge base
    qvec_kb = nlp_utils.tfidf_vector(tokens, kb_vocab, kb_df, kb_N)
    best_kb_idx, best_kb_score = None, 0.0
    for i, dvec in enumerate(kb_vectors):
        s = nlp_utils.cosine_sim(qvec_kb, dvec)
        if s > best_kb_score:
            best_kb_idx, best_kb_score = i, s
    print(f"DEBUG => KB score: {best_kb_score:.3f}")

    if best_kb_idx is not None and best_kb_score > 0.15:
        reply = knowledge_base[best_kb_idx]["a"]
        context.add_message("bot", reply)
        return {"reply": reply}

    # 5) fallback final
    reply = smart_reply(user_text)
    context.add_message("bot", reply)
    return {"reply": reply}

# ---------------- CONTEXT MANAGEMENT ----------------
@app.get("/context")
def get_context():
    return {"context": context.get_context()}

@app.delete("/context")
def clear_context():
    context.clear_context()
    return {"status": "cleared"}

# -------------------- USER PROFILE MANAGEMENT --------------------
@app.get("/profile")
def list_profile():
    """ReturneazÄƒ toate informaÈ›iile din profilul personal."""
    prof = db.get_profile()
    results = [{"id": i+1, "category": cat, "info": info} for i, (cat, info) in enumerate(prof)]
    return {"profile": results}

@app.put("/profile/{profile_id}")
def update_profile(profile_id: int, msg: Message):
    """ActualizeazÄƒ o intrare din profilul personal."""
    conn = db.get_connection()
    cur = conn.cursor()
    cur.execute("UPDATE user_profile SET info=? WHERE id=?", (msg.message, profile_id))
    conn.commit()
    conn.close()
    return {"status": "updated", "id": profile_id, "new_info": msg.message}

@app.delete("/profile/{profile_id}")
def delete_profile(profile_id: int):
    """È˜terge o intrare din profilul personal."""
    db.delete_profile_entry(profile_id)
    return {"status": "deleted", "id": profile_id}

# ---------------- STATIC FRONTEND ----------------
app.mount("/", StaticFiles(directory="static", html=True), name="static")
